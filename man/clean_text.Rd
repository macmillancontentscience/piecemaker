% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/clean.R
\name{clean_text}
\alias{clean_text}
\title{Prepare Text for Tokenization}
\usage{
clean_text(
  text,
  whitespace = TRUE,
  control_characters = TRUE,
  replacement_characters = TRUE,
  diacritics = TRUE
)
}
\arguments{
\item{text}{A character vector to clean.}

\item{whitespace}{Logical scalar; should we squish whitespace characters
(using \code{\link[stringr]{str_squish}})?}

\item{control_characters}{Logical scalar; should we remove control
characters?}

\item{diacritics}{Logical scalar; should we remove diacritical marks
(accents, etc) from characters?}

\item{remove_replacement_characters}{Logical scalar; should we remove the
"replacement character", \code{U-FFFD}?}
}
\value{
The character vector, cleaned as specified.
}
\description{
This function combines the other functions in this package to prepare text
for tokenization. The text gets converted to valid UTF-8 (if possible), and
then various cleaning functions are applied.
}
\examples{
piece1 <- " This is a    \n\nfa\xE7ile\n\n    example.\n"
# Specify encoding so this example behaves the same on all systems.
Encoding(piece1) <- "latin1"
example_text <- paste(
  piece1,
  "It has the bell character, \a, and the replacement character,",
  intToUtf8(65533)
)
clean_text(example_text)
clean_text(example_text, whitespace = FALSE)
clean_text(example_text, control_characters = FALSE)
clean_text(example_text, replacement_characters = FALSE)
clean_text(example_text, diacritics = FALSE)
}
