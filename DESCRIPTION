Package: piecemaker
Title: Tools for Preparing Text for Tokenizers
Version: 0.0.0.9000
Authors@R: c(
    person(given = "Jon",
           family = "Harmon",
           role = c("aut", "cre"),
           email = "jonthegeek@gmail.com",
           comment = c(ORCID = "0000-0003-4781-4346")),
    person(given = "Jonathan",
           family = "Bratt",
           role = c("aut"),
           email = "jonathan.bratt@macmillan.com",
           comment = c(ORCID = "0000-0003-2859-0076")),
    person(given = "Bedford Freeman & Worth Pub Grp LLC DBA Macmillan Learning", 
           role = c("cph"))
    )
Description: Tokenizers break text into pieces that are more usable by machine 
    learning models. Many tokenizers share some preparation steps. This package
    provides those shared steps.
License: MIT + file LICENSE
Encoding: UTF-8
LazyData: true
Roxygen: list(markdown = TRUE)
RoxygenNote: 7.1.1
